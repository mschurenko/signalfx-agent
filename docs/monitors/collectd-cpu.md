<!--- GENERATED BY gomplate from scripts/docs/monitor-page.md.tmpl --->

# collectd/cpu

This monitor collects cpu usage data using the
collectd `cpu` plugin.  It aggregates the per-core CPU data into a single
metric and sends it to the SignalFx Metadata plugin in collectd, where the
raw jiffy counts from the `cpu` plugin are converted to percent utilization
(the `cpu.utilization` metric).

See https://collectd.org/wiki/index.php/Plugin:CPU


Monitor Type: `collectd/cpu`

[Monitor Source Code](https://github.com/signalfx/signalfx-agent/tree/master/internal/monitors/collectd/cpu)

**Accepts Endpoints**: No

**Multiple Instances Allowed**: **No**

## Configuration

This monitor has no configuration options.


## Metrics

The following table lists the metrics available for this monitor. Metrics that are marked as Included are standard metrics and are monitored by default.

| Name | Type | Included | Description |
| ---  | ---  | ---    | ---         |
| `cpu.idle` | cumulative |  | CPU time spent not in any other state. In order to get a percentage this value must be compared against the sum of all CPU states. |
| `cpu.interrupt` | cumulative |  | CPU time spent while servicing hardware interrupts -- A hardware interrupt happens at the physical layer. When this occurs, the CPU will stop whatever else it is doing and service the interrupt. This metric measures how many jiffies were spent handling these interrupts. In order to get a percentage this value must be compared against the sum of all CPU states. A sustained high value for this metric may be caused by faulty hardware such as a broken peripheral. |
| `cpu.nice` | cumulative |  | CPU time spent in userspace running 'nice'-ed processes. In order to get a percentage this value must be compared against the sum of all CPU states. A sustained high value for this metric may be caused by: 1) The server not having enough CPU capacity for a process, 2) A programming error which causes a process to use an unexpected amount of CPU |
| `cpu.softirq` | cumulative |  | CPU time spent while servicing software interrupts -- unlike a hardware interrupt, a software interrupt happens at the sofware layer. Usually it is a userspace program requesting a service of the kernel. This metric measures how many jiffies were spent by the CPU handling these interrupts. In order to get a percentage this value must be compared against the sum of all CPU states. A sustained high value for this metric may be caused by a programming error which causes a process to unexpectedly request too many services from the kernel. |
| `cpu.steal` | cumulative |  | CPU time spent waiting for a hypervisor to service requests from other virtual machines -- This metric is only present on virtual machines. This metric records how much time this virtual machine had to wait to have the hypervisor kernel service a request. In order to get a percentage this value must be compared against the sum of all CPU states. A sustained high value for this metric may be caused by: 1) Another VM on the same hypervisor using too many resources, or 2) An underpowered hypervisor |
| `cpu.system` | cumulative |  | CPU time spent running in the kernel -- This value reflects how often processes are calling into the kernel for services (e.g to log to the console). In order to get a percentage this value must be compared against the sum of all CPU states. A sustained high value for this metric may be caused by: 1) A process that needs to be re-written to use kernel resources more efficiently, or 2) A userspace driver that is broken |
| `cpu.user` | cumulative |  | CPU time spent running in userspace -- In order to get a percentage this value must be compared against the sum of all CPU states. If this value is high: 1) A process requires more CPU to run than is available on the server, or 2) There is an application programming error which is causing the CPU to be used unexpectedly. |
| `cpu.wait` | cumulative |  | Amount of total CPU time spent idle while waiting for an I/O operation to complete -- In order to get a percentage this value must be compared against the sum of all CPU states. A high value for a sustained period may be caused by: 1) A slow hardware device that is taking too long to service requests, or 2) Too many requests being sent to an I/O device |


To specify custom metrics you want to monitor, add a `metricsToInclude` filter
to the agent configuration, as shown in the code snippet below. The snippet
lists all available custom metrics. You can copy and paste the snippet into
your configuration file, then delete any custom metrics that you do not want
sent.

Note that some of the custom metrics require you to set a flag as well as add
them to the list. Check the monitor configuration file to see if a flag is
required for gathering additional metrics.

```yaml

metricsToInclude:
  - metricNames:
    - cpu.idle
    - cpu.interrupt
    - cpu.nice
    - cpu.softirq
    - cpu.steal
    - cpu.system
    - cpu.user
    - cpu.wait
    monitorType: collectd/cpu
```




